{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "from typing import Optional, Dict, Any, List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LongBeachAnimalShelterAPI:\n",
    "    \"\"\"\n",
    "    A Python client for extracting data from the Long Beach Animal Shelter API\n",
    "    using the Opendatasoft Explore API v2.1\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.base_url = \"https://longbeach.opendatasoft.com/api/explore/v2.1\"\n",
    "        self.dataset_id = \"animal-shelter-intakes-and-outcomes\"\n",
    "        \n",
    "    def get_all_records(self, \n",
    "                       select: Optional[str] = None,\n",
    "                       where: Optional[str] = None,\n",
    "                       order_by: Optional[str] = None) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Extract all records from the animal shelter dataset without limits.\n",
    "        \n",
    "        Args:\n",
    "            select: Fields to select (default: all fields)\n",
    "            where: Filter conditions using ODSQL syntax\n",
    "            order_by: Order by clause\n",
    "            \n",
    "        Returns:\n",
    "            pandas.DataFrame with all records\n",
    "        \"\"\"\n",
    "        \n",
    "        all_records = []\n",
    "        offset = 0\n",
    "        limit = 100  # Maximum allowed per request\n",
    "        \n",
    "        while True:\n",
    "            # Build API request\n",
    "            url = f\"{self.base_url}/catalog/datasets/{self.dataset_id}/records\"\n",
    "            \n",
    "            params = {\n",
    "                'limit': limit,\n",
    "                'offset': offset\n",
    "            }\n",
    "            \n",
    "            # Add optional parameters\n",
    "            if select:\n",
    "                params['select'] = select\n",
    "            if where:\n",
    "                params['where'] = where\n",
    "            if order_by:\n",
    "                params['order_by'] = order_by\n",
    "                \n",
    "            try:\n",
    "                response = requests.get(url, params=params)\n",
    "                response.raise_for_status()\n",
    "                \n",
    "                data = response.json()\n",
    "                \n",
    "                # Extract records from response\n",
    "                records = data.get('results', [])\n",
    "                \n",
    "                if not records:\n",
    "                    break\n",
    "                    \n",
    "                all_records.extend(records)\n",
    "                \n",
    "                # Check if we've retrieved all records\n",
    "                total_count = data.get('total_count', 0)\n",
    "                if len(all_records) >= total_count:\n",
    "                    break\n",
    "                    \n",
    "                # Move to next batch\n",
    "                offset += limit\n",
    "                \n",
    "                print(f\"Retrieved {len(all_records)} of {total_count} records...\")\n",
    "                \n",
    "            except requests.RequestException as e:\n",
    "                print(f\"Error fetching data: {e}\")\n",
    "                break\n",
    "                \n",
    "        # Convert to DataFrame\n",
    "        df = pd.DataFrame(all_records)\n",
    "        print(f\"Successfully retrieved {len(df)} total records\")\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def get_dataset_info(self) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Get metadata about the dataset including field information.\n",
    "        \n",
    "        Returns:\n",
    "            Dictionary with dataset metadata\n",
    "        \"\"\"\n",
    "        url = f\"{self.base_url}/catalog/datasets/{self.dataset_id}\"\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()\n",
    "            return response.json()\n",
    "            \n",
    "        except requests.RequestException as e:\n",
    "            print(f\"Error fetching dataset info: {e}\")\n",
    "            return {}\n",
    "    \n",
    "    def export_to_csv(self, \n",
    "                     filename: str = \"animal_shelter_data.csv\",\n",
    "                     select: Optional[str] = None,\n",
    "                     where: Optional[str] = None) -> bool:\n",
    "        \"\"\"\n",
    "        Export data directly to CSV using the API's export endpoint.\n",
    "        \n",
    "        Args:\n",
    "            filename: Output CSV filename\n",
    "            select: Fields to select\n",
    "            where: Filter conditions\n",
    "            \n",
    "        Returns:\n",
    "            True if successful, False otherwise\n",
    "        \"\"\"\n",
    "        url = f\"{self.base_url}/catalog/datasets/{self.dataset_id}/exports/csv\"\n",
    "        \n",
    "        params = {'limit': -1}  # -1 means no limit for exports\n",
    "        \n",
    "        if select:\n",
    "            params['select'] = select\n",
    "        if where:\n",
    "            params['where'] = where\n",
    "            \n",
    "        try:\n",
    "            response = requests.get(url, params=params)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            with open(filename, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "                \n",
    "            print(f\"Data exported to {filename}\")\n",
    "            return True\n",
    "            \n",
    "        except requests.RequestException as e:\n",
    "            print(f\"Error exporting data: {e}\")\n",
    "            return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching all animal shelter records...\n",
      "Retrieved 100 of 32487 records...\n",
      "Retrieved 200 of 32487 records...\n",
      "Retrieved 300 of 32487 records...\n",
      "Retrieved 400 of 32487 records...\n",
      "Retrieved 500 of 32487 records...\n",
      "Retrieved 600 of 32487 records...\n",
      "Retrieved 700 of 32487 records...\n",
      "Retrieved 800 of 32487 records...\n",
      "Retrieved 900 of 32487 records...\n",
      "Retrieved 1000 of 32487 records...\n",
      "Retrieved 1100 of 32487 records...\n",
      "Retrieved 1200 of 32487 records...\n",
      "Retrieved 1300 of 32487 records...\n",
      "Retrieved 1400 of 32487 records...\n",
      "Retrieved 1500 of 32487 records...\n",
      "Retrieved 1600 of 32487 records...\n",
      "Retrieved 1700 of 32487 records...\n",
      "Retrieved 1800 of 32487 records...\n",
      "Retrieved 1900 of 32487 records...\n",
      "Retrieved 2000 of 32487 records...\n",
      "Retrieved 2100 of 32487 records...\n",
      "Retrieved 2200 of 32487 records...\n",
      "Retrieved 2300 of 32487 records...\n",
      "Retrieved 2400 of 32487 records...\n",
      "Retrieved 2500 of 32487 records...\n",
      "Retrieved 2600 of 32487 records...\n",
      "Retrieved 2700 of 32487 records...\n",
      "Retrieved 2800 of 32487 records...\n",
      "Retrieved 2900 of 32487 records...\n",
      "Retrieved 3000 of 32487 records...\n",
      "Retrieved 3100 of 32487 records...\n",
      "Retrieved 3200 of 32487 records...\n",
      "Retrieved 3300 of 32487 records...\n",
      "Retrieved 3400 of 32487 records...\n",
      "Retrieved 3500 of 32487 records...\n",
      "Retrieved 3600 of 32487 records...\n",
      "Retrieved 3700 of 32487 records...\n",
      "Retrieved 3800 of 32487 records...\n",
      "Retrieved 3900 of 32487 records...\n",
      "Retrieved 4000 of 32487 records...\n",
      "Retrieved 4100 of 32487 records...\n",
      "Retrieved 4200 of 32487 records...\n",
      "Retrieved 4300 of 32487 records...\n",
      "Retrieved 4400 of 32487 records...\n",
      "Retrieved 4500 of 32487 records...\n",
      "Retrieved 4600 of 32487 records...\n",
      "Retrieved 4700 of 32487 records...\n",
      "Retrieved 4800 of 32487 records...\n",
      "Retrieved 4900 of 32487 records...\n",
      "Retrieved 5000 of 32487 records...\n",
      "Retrieved 5100 of 32487 records...\n",
      "Retrieved 5200 of 32487 records...\n",
      "Retrieved 5300 of 32487 records...\n",
      "Retrieved 5400 of 32487 records...\n",
      "Retrieved 5500 of 32487 records...\n",
      "Retrieved 5600 of 32487 records...\n",
      "Retrieved 5700 of 32487 records...\n",
      "Retrieved 5800 of 32487 records...\n",
      "Retrieved 5900 of 32487 records...\n",
      "Retrieved 6000 of 32487 records...\n",
      "Retrieved 6100 of 32487 records...\n",
      "Retrieved 6200 of 32487 records...\n",
      "Retrieved 6300 of 32487 records...\n",
      "Retrieved 6400 of 32487 records...\n",
      "Retrieved 6500 of 32487 records...\n",
      "Retrieved 6600 of 32487 records...\n",
      "Retrieved 6700 of 32487 records...\n",
      "Retrieved 6800 of 32487 records...\n",
      "Retrieved 6900 of 32487 records...\n",
      "Retrieved 7000 of 32487 records...\n",
      "Retrieved 7100 of 32487 records...\n",
      "Retrieved 7200 of 32487 records...\n",
      "Retrieved 7300 of 32487 records...\n",
      "Retrieved 7400 of 32487 records...\n",
      "Retrieved 7500 of 32487 records...\n",
      "Retrieved 7600 of 32487 records...\n",
      "Retrieved 7700 of 32487 records...\n",
      "Retrieved 7800 of 32487 records...\n",
      "Retrieved 7900 of 32487 records...\n",
      "Retrieved 8000 of 32487 records...\n",
      "Retrieved 8100 of 32487 records...\n",
      "Retrieved 8200 of 32487 records...\n",
      "Retrieved 8300 of 32487 records...\n",
      "Retrieved 8400 of 32487 records...\n",
      "Retrieved 8500 of 32487 records...\n",
      "Retrieved 8600 of 32487 records...\n",
      "Retrieved 8700 of 32487 records...\n",
      "Retrieved 8800 of 32487 records...\n",
      "Retrieved 8900 of 32487 records...\n",
      "Retrieved 9000 of 32487 records...\n",
      "Retrieved 9100 of 32487 records...\n",
      "Retrieved 9200 of 32487 records...\n",
      "Retrieved 9300 of 32487 records...\n",
      "Retrieved 9400 of 32487 records...\n",
      "Retrieved 9500 of 32487 records...\n",
      "Retrieved 9600 of 32487 records...\n",
      "Retrieved 9700 of 32487 records...\n",
      "Retrieved 9800 of 32487 records...\n",
      "Retrieved 9900 of 32487 records...\n",
      "Retrieved 10000 of 32487 records...\n",
      "Error fetching data: 400 Client Error: Bad Request for url: https://longbeach.opendatasoft.com/api/explore/v2.1/catalog/datasets/animal-shelter-intakes-and-outcomes/records?limit=100&offset=10000\n",
      "Successfully retrieved 10000 total records\n",
      "Retrieved 10000 records\n",
      "Columns: ['animal_id', 'animal_name', 'animal_type', 'primary_color', 'secondary_color', 'sex', 'dob', 'intake_date', 'intake_cond', 'intake_type', 'intake_subtype', 'reason', 'outcome_date', 'crossing', 'jurisdiction', 'outcome_type', 'outcome_subtype', 'latitude', 'longitude', 'intake_is_dead', 'outcome_is_dead', 'was_outcome_alive', 'geopoint']\n",
      "\n",
      "Exporting all data to CSV...\n",
      "Data exported to longbeach_animal_shelter_complete.csv\n",
      "\n",
      "Sample data:\n",
      "  animal_id animal_name animal_type primary_color secondary_color      sex  \\\n",
      "0   A598453        None         DOG         WHITE           BROWN   Female   \n",
      "1   A595873        None        WILD         BROWN            None  Unknown   \n",
      "2   A677157        None         CAT          GRAY           WHITE     Male   \n",
      "3   A731052     *GINGER         DOG         BROWN           BLACK   Spayed   \n",
      "4   A635910        None         CAT       BLUE PT           WHITE     Male   \n",
      "\n",
      "          dob intake_date        intake_cond intake_type  ...  \\\n",
      "0  2012-10-08  2017-10-08             NORMAL       STRAY  ...   \n",
      "1        None  2017-08-23  INJURED  MODERATE    WILDLIFE  ...   \n",
      "2  2021-12-10  2022-06-10    INJURED  SEVERE       STRAY  ...   \n",
      "3  2021-10-23  2024-10-23             NORMAL       STRAY  ...   \n",
      "4  2019-09-08  2019-11-08             NORMAL       STRAY  ...   \n",
      "\n",
      "                                 crossing jurisdiction outcome_type  \\\n",
      "0    2300 E 15TH ST, LONG BEACH, CA 90804   LONG BEACH     TRANSFER   \n",
      "1    2300 E 17TH ST, LONG BEACH, CA 90804   LONG BEACH     TRANSFER   \n",
      "2     2300 EASY AVE, LONG BEACH, CA 90810   LONG BEACH   EUTHANASIA   \n",
      "3   2300 LEWIS AVE, SIGNAL HILL, CA 90755  SIGNAL HILL     ADOPTION   \n",
      "4  2300 REDONDO AVE SIGNAL HILL, CA 90755  SIGNAL HILL       RESCUE   \n",
      "\n",
      "  outcome_subtype   latitude   longitude   intake_is_dead  outcome_is_dead  \\\n",
      "0          SPCALA  33.785840 -118.164405  Alive on Intake            FALSE   \n",
      "1            LBAH  33.788044 -118.164770  Alive on Intake            FALSE   \n",
      "2      INJ SEVERE  33.798961 -118.210018  Alive on Intake             TRUE   \n",
      "3             WEB  33.799293 -118.179409  Alive on Intake            FALSE   \n",
      "4         CATPAWS  33.799479 -118.149571  Alive on Intake            FALSE   \n",
      "\n",
      "   was_outcome_alive                                  geopoint  \n",
      "0                  1  {'lon': -118.1644052, 'lat': 33.7858395}  \n",
      "1                  1   {'lon': -118.1647702, 'lat': 33.788044}  \n",
      "2                  0  {'lon': -118.2100175, 'lat': 33.7989612}  \n",
      "3                  1  {'lon': -118.1794086, 'lat': 33.7992932}  \n",
      "4                  1   {'lon': -118.1495712, 'lat': 33.799479}  \n",
      "\n",
      "[5 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # Initialize the API client\n",
    "    api = LongBeachAnimalShelterAPI()\n",
    "    \n",
    "    # Example 1: Get all records\n",
    "    print(\"Fetching all animal shelter records...\")\n",
    "    df = api.get_all_records()\n",
    "    print(f\"Retrieved {len(df)} records\")\n",
    "    print(f\"Columns: {list(df.columns)}\")\n",
    "    \n",
    "    \n",
    "    # Example 5: Export directly to CSV\n",
    "    print(\"\\nExporting all data to CSV...\")\n",
    "    api.export_to_csv(\"longbeach_animal_shelter_complete.csv\")\n",
    "    \n",
    "    \n",
    "    # Display sample data\n",
    "    if not df.empty:\n",
    "        print(\"\\nSample data:\")\n",
    "        print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"longbeach_animal_shelter_complete.csv\", sep=None, engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32487 entries, 0 to 32486\n",
      "Data columns (total 23 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   ﻿animal_id         32487 non-null  object \n",
      " 1   animal_name        19089 non-null  object \n",
      " 2   animal_type        32487 non-null  object \n",
      " 3   primary_color      32487 non-null  object \n",
      " 4   secondary_color    15487 non-null  object \n",
      " 5   sex                32487 non-null  object \n",
      " 6   dob                28391 non-null  object \n",
      " 7   intake_date        32487 non-null  object \n",
      " 8   intake_cond        32487 non-null  object \n",
      " 9   intake_type        32487 non-null  object \n",
      " 10  intake_subtype     32069 non-null  object \n",
      " 11  reason             2150 non-null   object \n",
      " 12  outcome_date       32211 non-null  object \n",
      " 13  crossing           32487 non-null  object \n",
      " 14  jurisdiction       32486 non-null  object \n",
      " 15  outcome_type       32202 non-null  object \n",
      " 16  outcome_subtype    28720 non-null  object \n",
      " 17  latitude           32487 non-null  float64\n",
      " 18  longitude          32487 non-null  float64\n",
      " 19  intake_is_dead     32487 non-null  object \n",
      " 20  outcome_is_dead    32487 non-null  bool   \n",
      " 21  was_outcome_alive  32487 non-null  int64  \n",
      " 22  geopoint           32487 non-null  object \n",
      "dtypes: bool(1), float64(2), int64(1), object(19)\n",
      "memory usage: 5.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "community-capstone-X1y0cgVF-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
