{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a28fd7e",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b923faab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from missingno import matrix\n",
    "from fastai.tabular.core import add_datepart\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.cluster import DBSCAN, AgglomerativeClustering, KMeans, AffinityPropagation, SpectralClustering\n",
    "from kmodes.kprototypes import KPrototypes\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "import gower\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48bf8b37",
   "metadata": {},
   "source": [
    "# Data pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a684e7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"longbeach_animal_shelter_complete.csv\", sep=None, engine='python')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962c5661",
   "metadata": {},
   "source": [
    "# Data transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89af0cb5",
   "metadata": {},
   "source": [
    "## Removing whitespaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c1291d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.strip().str.replace('\\ufeff', '') # Removing whitespaces in column names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63858083",
   "metadata": {},
   "source": [
    "## Date time conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a021b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert *dob*, *intake_date*, *outcome_date* to datetime\n",
    "df['dob'] = pd.to_datetime(df['dob'], errors='coerce')\n",
    "df['intake_date'] = pd.to_datetime(df['intake_date'], errors='coerce')\n",
    "df['outcome_date'] = pd.to_datetime(df['outcome_date'], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cac1526",
   "metadata": {},
   "source": [
    "## Adding time to outcome variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c902c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['time_to_outcome'] = df['outcome_date'] - df['intake_date'] # Calculate time to outcome in days"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6688830b",
   "metadata": {},
   "source": [
    "## Dealing with duplicates\n",
    "\n",
    "In this context, duplicate animal IDs reflect returning animals. This analysis will keep counts for returning cases, note time time between visits, and identify animals that return more than twice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bf985a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(['animal_id', 'intake_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd09e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visit_count using groupby and cumcount\n",
    "df['visit_count'] = df.groupby('animal_id').cumcount() + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b5037f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional useful features\n",
    "df['is_return_visit'] = (df['visit_count'] > 1).astype(int)\n",
    "df['is_frequent_returner'] = (df['visit_count'] > 2).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b253cca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced features for return animals\n",
    "df['days_since_last_visit'] = df.groupby('animal_id')['intake_date'].diff().dt.days\n",
    "df['days_since_last_visit'] = df['days_since_last_visit'].fillna(-1)\n",
    "df['previous_outcome_type'] = df.groupby('animal_id')['outcome_type'].shift(1)\n",
    "df['previous_outcome_type'] = df['previous_outcome_type'].fillna('First Visit')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52ac4ef",
   "metadata": {},
   "source": [
    "## Date of birth imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2a8a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_dob_statistical(df):\n",
    "    \"\"\"Impute DOB using statistical measures from similar animals\"\"\"\n",
    "    df_imputed = df.copy()\n",
    "    \n",
    "    # Calculate age for animals with known DOB\n",
    "    known_mask = df_imputed['dob'].notna()\n",
    "    df_imputed.loc[known_mask, 'age_at_intake_days'] = (\n",
    "        df_imputed.loc[known_mask, 'intake_date'] - df_imputed.loc[known_mask, 'dob']\n",
    "    ).dt.days\n",
    "    \n",
    "    # Group by animal_type and intake_type for imputation\n",
    "    imputation_groups = ['animal_type', 'intake_type', 'sex']\n",
    "    \n",
    "    missing_mask = df_imputed['dob'].isna()\n",
    "    imputed_count = 0\n",
    "    \n",
    "    for idx in df_imputed[missing_mask].index:\n",
    "        # Get characteristics of current animal\n",
    "        animal_info = df_imputed.loc[idx]\n",
    "        \n",
    "        # Find similar animals with known DOB\n",
    "        similar_animals = df_imputed[\n",
    "            (df_imputed['animal_type'] == animal_info['animal_type']) &\n",
    "            (df_imputed['intake_type'] == animal_info['intake_type']) &\n",
    "            (df_imputed['sex'] == animal_info['sex']) &\n",
    "            (df_imputed['dob'].notna())\n",
    "        ]\n",
    "        \n",
    "        # If no exact match, broaden the criteria\n",
    "        if len(similar_animals) < 5:\n",
    "            similar_animals = df_imputed[\n",
    "                (df_imputed['animal_type'] == animal_info['animal_type']) &\n",
    "                (df_imputed['intake_type'] == animal_info['intake_type']) &\n",
    "                (df_imputed['dob'].notna())\n",
    "            ]\n",
    "        \n",
    "        # If still no match, use animal_type only\n",
    "        if len(similar_animals) < 5:\n",
    "            similar_animals = df_imputed[\n",
    "                (df_imputed['animal_type'] == animal_info['animal_type']) &\n",
    "                (df_imputed['dob'].notna())\n",
    "            ]\n",
    "        \n",
    "        if len(similar_animals) > 0:\n",
    "            # Use median age of similar animals\n",
    "            median_age_days = similar_animals['age_at_intake_days'].median()\n",
    "            \n",
    "            # FIX: Check if median is valid and convert to int\n",
    "            if pd.notna(median_age_days):\n",
    "                # Calculate imputed DOB\n",
    "                imputed_dob = animal_info['intake_date'] - timedelta(days=int(median_age_days))\n",
    "                df_imputed.loc[idx, 'dob'] = imputed_dob\n",
    "                imputed_count += 1\n",
    "    \n",
    "    print(f\"Strategy 1: Imputed DOB for {imputed_count} animals using statistical method\")\n",
    "    return df_imputed\n",
    "\n",
    "def impute_dob_domain_knowledge(df):\n",
    "    \"\"\"Impute DOB using domain knowledge about animal shelters\"\"\"\n",
    "    df_imputed = df.copy()\n",
    "    \n",
    "    missing_mask = df_imputed['dob'].isna()\n",
    "    imputed_count = 0\n",
    "    \n",
    "    for idx in df_imputed[missing_mask].index:\n",
    "        animal_info = df_imputed.loc[idx]\n",
    "        intake_date = animal_info['intake_date']\n",
    "        \n",
    "        # Define typical ages based on intake type and condition\n",
    "        if animal_info['intake_type'] == 'WILDLIFE':\n",
    "            # Wildlife often comes in as injured adults or orphaned babies\n",
    "            if 'WEIGHT' in str(animal_info['intake_cond']).upper():\n",
    "                # Likely a baby if underweight\n",
    "                estimated_age_days = np.random.normal(30, 15)  # 1 month ± 2 weeks\n",
    "            else:\n",
    "                # Likely adult wildlife\n",
    "                estimated_age_days = np.random.normal(365, 180)  # 1 year ± 6 months\n",
    "                \n",
    "        elif animal_info['intake_type'] == 'STRAY':\n",
    "            # Strays are often young adults who got lost\n",
    "            if animal_info['animal_type'] == 'CAT':\n",
    "                estimated_age_days = np.random.normal(548, 365)  # 1.5 years ± 1 year\n",
    "            else:  # DOG\n",
    "                estimated_age_days = np.random.normal(730, 365)  # 2 years ± 1 year\n",
    "                \n",
    "        elif animal_info['intake_type'] == 'OWNER SURRENDER':\n",
    "            # Owner surrenders often older animals due to life changes\n",
    "            if animal_info['animal_type'] == 'CAT':\n",
    "                estimated_age_days = np.random.normal(1095, 730)  # 3 years ± 2 years\n",
    "            else:  # DOG\n",
    "                estimated_age_days = np.random.normal(1460, 1095)  # 4 years ± 3 years\n",
    "                \n",
    "        else:\n",
    "            # Default for other types\n",
    "            estimated_age_days = np.random.normal(365, 180)  # 1 year ± 6 months\n",
    "        \n",
    "        # Ensure positive age and not born in the future\n",
    "        estimated_age_days = max(1, estimated_age_days)\n",
    "        estimated_age_days = min(estimated_age_days, 5475)  # Max 15 years\n",
    "        \n",
    "        # FIX: Convert to int for timedelta\n",
    "        # Calculate DOB\n",
    "        imputed_dob = intake_date - timedelta(days=int(estimated_age_days))\n",
    "        df_imputed.loc[idx, 'dob'] = imputed_dob\n",
    "        imputed_count += 1\n",
    "    \n",
    "    print(f\"Strategy 2: Imputed DOB for {imputed_count} animals using domain knowledge\")\n",
    "    return df_imputed\n",
    "\n",
    "def impute_dob_hybrid(df):\n",
    "    \"\"\"Combine multiple strategies for best results\"\"\"\n",
    "    df_imputed = df.copy()\n",
    "    \n",
    "    print(\"Hybrid DOB Imputation Strategy:\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # First, try statistical imputation for animals with many similar examples\n",
    "    df_imputed = impute_dob_statistical(df_imputed)\n",
    "    \n",
    "    # Then, use domain knowledge for remaining missing values\n",
    "    remaining_missing = df_imputed['dob'].isna().sum()\n",
    "    if remaining_missing > 0:\n",
    "        print(f\"Applying domain knowledge to {remaining_missing} remaining missing DOBs\")\n",
    "        df_imputed = impute_dob_domain_knowledge(df_imputed)\n",
    "    # Calculate age for ALL animals after imputation\n",
    "    df_imputed['age_at_intake_days'] = (df_imputed['intake_date'] - df_imputed['dob']).dt.days\n",
    "    \n",
    "    return df_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4bb5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = impute_dob_hybrid(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc622e3a",
   "metadata": {},
   "source": [
    "## Deleting values where DOB is after intake date\n",
    "This measure is undertaken to ensure logical consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a49a032",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df['dob'] <= df['intake_date']) | df['dob'].isnull() | df['intake_date'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21dab649",
   "metadata": {},
   "source": [
    "## Replace null values of secondary color to 'None'\n",
    "\n",
    "This step can help classify animals with more colours/patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0d1a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['secondary_color'] = df['secondary_color'].fillna('None')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7edb715",
   "metadata": {},
   "source": [
    "## Dropping columns *reason*, *geopoint*, *was_outcome_alive*, *animal_id*\n",
    "\n",
    "These features either don't convey any information, or, contain too many null values to impute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf772f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['reason', 'geopoint', 'was_outcome_alive', 'animal_id'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40be6920",
   "metadata": {},
   "source": [
    "## Making a binary column for name of animal\n",
    "\n",
    "A binary variable with a name indicator is better for classification ML models instead of the name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db19a1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New column called has_name where if animal_name is not null, then 1, else 0\n",
    "df['has_name'] = df['animal_name'].notnull().astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50b972c",
   "metadata": {},
   "source": [
    "## Dropping animal_name column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcbe95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['animal_name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec81eab",
   "metadata": {},
   "source": [
    "## Dropping null values for outocme_type & intake_subtype\n",
    "\n",
    "The target variable nulls are small in number and would be better off excluded from the analysis. \n",
    "\n",
    "Knowing more about the intake reason will help the analysis become robust."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa6a51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['intake_subtype', 'outcome_type'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9593bbd4",
   "metadata": {},
   "source": [
    "## Dropping the *crossing* feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0607fd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['crossing'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef93427c",
   "metadata": {},
   "source": [
    "## Dropping *intake_is_dead* column\n",
    "\n",
    "Can drop this column since no information is being conveyed through only 1 possible outcome here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baea0fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['intake_is_dead'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed857591",
   "metadata": {},
   "source": [
    "## Intake month feature creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cba909",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['intake_month'] = df['intake_date'].dt.month"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0c736a",
   "metadata": {},
   "source": [
    "## Adding *is_fixed* column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304a76cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_fixed'] = df['sex'].str.contains('Spayed|Neutered', case=False, na=False).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2c8094",
   "metadata": {},
   "source": [
    "## Making changes to the *sex* column\n",
    "\n",
    "Since the sex column contains the fix status, we want to change that to just male, female, and unknown options. The way we can do that is by changing \"neutered\" to male and \"spayed\" to female"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18764355",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sex'] = df['sex'].replace({'Neutered': 'Male', 'Spayed': 'Female'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d256ea0e",
   "metadata": {},
   "source": [
    "## Datetime feature engineering using fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8f7b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for col in ['dob','intake_date','outcome_date']:\n",
    "    df[col] = pd.to_datetime(df[col], utc=True)\n",
    "\n",
    "# Explode each date column into date‐parts + an “Elapsed” (epoch seconds)\n",
    "for col in ['dob','intake_date','outcome_date']:\n",
    "    add_datepart(df, col, drop=True)  # drop=True removes the original datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49769c26",
   "metadata": {},
   "source": [
    "## Dropping redundant date columns\n",
    "\n",
    "Some date columns created above don't add meaningful information to the analysis and are thus, dropped. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0400314",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['intake_month', 'intake_Year', 'intake_Week', 'intake_Day', 'intake_Dayofyear', 'intake_Is_month_end', 'intake_Is_month_start', 'intake_Is_quarter_end', 'intake_Is_quarter_start', 'intake_Is_year_end', 'intake_Is_year_start', 'outcome_Year','outcome_Week', 'outcome_Day', 'outcome_Dayofyear', 'outcome_Is_month_end', 'outcome_Is_month_start', 'outcome_Is_quarter_end', 'outcome_Is_quarter_start', 'outcome_Is_year_end', 'outcome_Is_year_start', 'dobYear', 'dobWeek', 'dobDay', 'dobIs_month_end', 'dobIs_month_start', 'dobIs_quarter_end', 'dobIs_quarter_start', 'dobIs_year_end', 'dobIs_year_start', 'dobDayofyear'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce0f566",
   "metadata": {},
   "source": [
    "## Dealing with features that have high cardinality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63f244c",
   "metadata": {},
   "source": [
    "### *primary_color*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72073a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_base_color_and_pattern(color):\n",
    "    \"\"\"Extract base color and pattern information from primary color\"\"\"\n",
    "    color = str(color).upper().strip()\n",
    "    \n",
    "    # Define pattern keywords\n",
    "    pattern_keywords = ['TABBY', 'BRINDLE', 'MERLE', 'PT', 'POINT', 'SMOKE', 'TIGER', 'LYNX']\n",
    "    \n",
    "    # Check if it has a pattern\n",
    "    has_pattern = any(keyword in color for keyword in pattern_keywords)\n",
    "    \n",
    "    # Extract base color\n",
    "    if color in ['TRICOLOR', 'CALICO', 'CALICO DIL', 'CALICO PT', 'CALICO TAB']:\n",
    "        base_color = 'Multicolor'\n",
    "    elif 'BLACK' in color or 'BLK' in color:\n",
    "        base_color = 'Black'\n",
    "    elif 'WHITE' in color:\n",
    "        base_color = 'White'\n",
    "    elif 'BROWN' in color or 'BRN' in color or 'BR ' in color:\n",
    "        base_color = 'Brown'\n",
    "    elif 'GRAY' in color or 'GREY' in color:\n",
    "        base_color = 'Gray'\n",
    "    elif 'RED' in color or 'RD ' in color:\n",
    "        base_color = 'Red'\n",
    "    elif 'BLUE' in color or 'BL ' in color or 'BC ' in color:\n",
    "        base_color = 'Blue'\n",
    "    elif 'CREAM' in color or 'CRM' in color or 'CR ' in color:\n",
    "        base_color = 'Cream'\n",
    "    elif 'TAN' in color:\n",
    "        base_color = 'Tan'\n",
    "    elif 'YELLOW' in color:\n",
    "        base_color = 'Yellow'\n",
    "    elif 'ORANGE' in color or 'ORG' in color:\n",
    "        base_color = 'Orange'\n",
    "    elif 'GOLD' in color:\n",
    "        base_color = 'Gold'\n",
    "    elif 'SILVER' in color or 'SLVR' in color or 'SL ' in color:\n",
    "        base_color = 'Silver'\n",
    "    elif 'CHOCOLATE' in color or 'CHOC' in color or 'CH ' in color:\n",
    "        base_color = 'Chocolate'\n",
    "    elif 'BUFF' in color:\n",
    "        base_color = 'Buff'\n",
    "    elif 'BLONDE' in color:\n",
    "        base_color = 'Blonde'\n",
    "    elif 'APRICOT' in color:\n",
    "        base_color = 'Apricot'\n",
    "    elif 'TORTIE' in color or 'TORBI' in color:\n",
    "        base_color = 'Tortoiseshell'\n",
    "    elif 'SABLE' in color:\n",
    "        base_color = 'Sable'\n",
    "    elif 'WHEAT' in color:\n",
    "        base_color = 'Wheat'\n",
    "    elif 'FAWN' in color:\n",
    "        base_color = 'Fawn'\n",
    "    elif 'SEAL' in color:\n",
    "        base_color = 'Seal'\n",
    "    elif 'LILAC' in color:\n",
    "        base_color = 'Lilac'\n",
    "    elif 'LIVER' in color:\n",
    "        base_color = 'Liver'\n",
    "    elif 'PINK' in color:\n",
    "        base_color = 'Pink'\n",
    "    elif 'GREEN' in color:\n",
    "        base_color = 'Green'\n",
    "    elif 'FLAME' in color:\n",
    "        base_color = 'Flame'\n",
    "    elif 'PEACH' in color:\n",
    "        base_color = 'Peach'\n",
    "    elif 'RUDDY' in color:\n",
    "        base_color = 'Ruddy'\n",
    "    elif 'DAPPLE' in color:\n",
    "        base_color = 'Dapple'\n",
    "    elif 'SNOWSHOE' in color:\n",
    "        base_color = 'Snowshoe'\n",
    "    elif 'TICK' in color:\n",
    "        base_color = 'Tick'\n",
    "    elif 'UNKNOWN' in color:\n",
    "        base_color = 'Unknown'\n",
    "    else:\n",
    "        base_color = 'Other'\n",
    "    \n",
    "    return base_color, int(has_pattern)\n",
    "\n",
    "# Apply transformation\n",
    "print(\"Extracting base colors and patterns...\")\n",
    "primary_color_info = df['primary_color'].apply(extract_base_color_and_pattern)\n",
    "df['primary_base_color'] = [info[0] for info in primary_color_info]\n",
    "df['has_pattern'] = [info[1] for info in primary_color_info]\n",
    "\n",
    "# Display results\n",
    "print(\"Primary color transformation results:\")\n",
    "print(f\"primary_base_color unique values: {df['primary_base_color'].nunique()}\")\n",
    "print(\"Base color distribution:\")\n",
    "print(df['primary_base_color'].value_counts().head(10))\n",
    "print(f\"\\nPattern distribution:\")\n",
    "print(df['has_pattern'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ac0f51",
   "metadata": {},
   "source": [
    "### *secondary_color*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e597819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create binary secondary color feature\n",
    "df['has_secondary_color'] = (df['secondary_color'] != 'None').astype(int)\n",
    "\n",
    "print(\"Secondary color transformation results:\")\n",
    "print(\"has_secondary_color distribution:\")\n",
    "print(df['has_secondary_color'].value_counts())\n",
    "print(f\"Percentage with secondary color: {df['has_secondary_color'].mean()*100:.1f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRANSFORMING ANIMAL TYPE\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a80d0d",
   "metadata": {},
   "source": [
    "### *animal_type*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50e2f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_animal_type(animal_type):\n",
    "    \"\"\"Categorize animal type into Cat, Dog, Other\"\"\"\n",
    "    animal_type = str(animal_type).upper().strip()\n",
    "    \n",
    "    if animal_type == 'CAT':\n",
    "        return 'Cat'\n",
    "    elif animal_type == 'DOG':\n",
    "        return 'Dog'\n",
    "    else:  # OTHER, RABBIT, REPTILE, BIRD, LIVESTOCK, WILD, GUINEA PIG\n",
    "        return 'Other'\n",
    "\n",
    "# Apply transformation\n",
    "df['animal_type_grouped'] = df['animal_type'].apply(categorize_animal_type)\n",
    "\n",
    "print(\"Animal type transformation results:\")\n",
    "print(\"Original vs. Grouped:\")\n",
    "print(pd.crosstab(df['animal_type'], df['animal_type_grouped'], margins=True))\n",
    "\n",
    "print(\"\\nGrouped animal type distribution:\")\n",
    "print(df['animal_type_grouped'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f7bb9e",
   "metadata": {},
   "source": [
    "### *outcome_type*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2591f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_outcome_type(outcome_type):\n",
    "    \"\"\"Categorize outcome type into 6 main categories\"\"\"\n",
    "    outcome_type = str(outcome_type).upper().strip()\n",
    "    \n",
    "    if outcome_type == 'RESCUE':\n",
    "        return 'Rescue'\n",
    "    elif outcome_type == 'ADOPTION':\n",
    "        return 'Adoption'\n",
    "    elif outcome_type == 'EUTHANASIA':\n",
    "        return 'Euthanasia'\n",
    "    elif outcome_type == 'TRANSFER':\n",
    "        return 'Transfer'\n",
    "    elif outcome_type == 'RETURN TO OWNER':\n",
    "        return 'Return to Owner'\n",
    "    else:  # All other outcomes go to 'Other'\n",
    "        return 'Other'\n",
    "\n",
    "# Apply transformation\n",
    "df['outcome_type_grouped'] = df['outcome_type'].apply(categorize_outcome_type)\n",
    "\n",
    "print(\"Outcome type transformation results:\")\n",
    "print(\"Original vs. Grouped mapping:\")\n",
    "outcome_mapping = df.groupby('outcome_type')['outcome_type_grouped'].first().sort_values()\n",
    "for original, grouped in outcome_mapping.items():\n",
    "    count = (df['outcome_type'] == original).sum()\n",
    "    print(f\"  {original} → {grouped} ({count:,} records)\")\n",
    "\n",
    "print(\"\\nGrouped outcome type distribution:\")\n",
    "grouped_counts = df['outcome_type_grouped'].value_counts()\n",
    "for outcome, count in grouped_counts.items():\n",
    "    percentage = (count / len(df)) * 100\n",
    "    print(f\"  {outcome}: {count:,} ({percentage:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e715a95f",
   "metadata": {},
   "source": [
    "# ML Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6b2a72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b953f929",
   "metadata": {},
   "source": [
    "## Tree-based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a84e89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "88895e55",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33fe655",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "community-capstone-X1y0cgVF-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
